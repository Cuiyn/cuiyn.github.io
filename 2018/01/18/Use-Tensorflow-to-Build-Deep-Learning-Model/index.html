<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.3.0/css/all.min.css" integrity="sha256-/4UQcSmErDzPCMAiuOiWPVVsNN2s3ZY/NsmXNcj0IFc=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"cuiyn.github.io","root":"/","images":"/images","scheme":"Muse","darkmode":false,"version":"8.15.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"}}</script><script src="/js/config.js"></script>

    <meta name="description" content="本文主要介绍如何使用Tensorflow框架作为深度学习的工具，构建模型并求解问题。">
<meta property="og:type" content="article">
<meta property="og:title" content="利用Tensorflow构建深度学习模型">
<meta property="og:url" content="http://cuiyn.github.io/2018/01/18/Use-Tensorflow-to-Build-Deep-Learning-Model/index.html">
<meta property="og:site_name" content="Cuiyn&#39;s Blog">
<meta property="og:description" content="本文主要介绍如何使用Tensorflow框架作为深度学习的工具，构建模型并求解问题。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://cuiyn.github.io/statics/images/20180118/tensors_flowing.gif">
<meta property="og:image" content="http://cuiyn.github.io/statics/images/20180118/example.jpg">
<meta property="og:image" content="http://cuiyn.github.io/statics/images/20180118/tensorflow_GPU.png">
<meta property="og:image" content="http://cuiyn.github.io/statics/images/20180118/MNIST-Matrix.png">
<meta property="article:published_time" content="2018-01-17T17:20:00.000Z">
<meta property="article:modified_time" content="2023-03-22T14:12:31.188Z">
<meta property="article:author" content="Cuiyn">
<meta property="article:tag" content="机器学习">
<meta property="article:tag" content="Batman">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://cuiyn.github.io/statics/images/20180118/tensors_flowing.gif">


<link rel="canonical" href="http://cuiyn.github.io/2018/01/18/Use-Tensorflow-to-Build-Deep-Learning-Model/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"http://cuiyn.github.io/2018/01/18/Use-Tensorflow-to-Build-Deep-Learning-Model/","path":"2018/01/18/Use-Tensorflow-to-Build-Deep-Learning-Model/","title":"利用Tensorflow构建深度学习模型"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>利用Tensorflow构建深度学习模型 | Cuiyn's Blog</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Cuiyn's Blog</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
    </div>
  </div>
</div>







</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Tensorflow%E6%A6%82%E8%BF%B0"><span class="nav-number">1.</span> <span class="nav-text">Tensorflow概述</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%AE%80%E4%BB%8B"><span class="nav-number">1.1.</span> <span class="nav-text">简介</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E7%A4%BA%E4%BE%8B"><span class="nav-number">1.2.</span> <span class="nav-text">一个简单示例</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%88%A9%E7%94%A8%E5%A4%9A%E4%B8%AAGPU%E5%8A%A0%E9%80%9F%E8%AE%A1%E7%AE%97"><span class="nav-number">1.3.</span> <span class="nav-text">利用多个GPU加速计算</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#MNIST%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB"><span class="nav-number">2.</span> <span class="nav-text">MNIST手写数字识别</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%9B%BE%E5%83%8F%E7%9A%84%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84"><span class="nav-number">2.1.</span> <span class="nav-text">图像的数据结构</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#softmax%E5%9B%9E%E5%BD%92"><span class="nav-number">2.2.</span> <span class="nav-text">softmax回归</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#h-theta-x-i-x3D-begin-bmatrix-p-y-i-x3D-1-x-i-theta-p-y-i-x3D-2-x-i-theta-vdots-p-y-i-x3D-k-x-i-theta-end-bmatrix"><span class="nav-number">3.</span> <span class="nav-text">$$h_\theta(x^{(i)}) &#x3D;\begin{bmatrix}p(y^{(i)} &#x3D; 1 | x^{(i)}; \theta) \p(y^{(i)} &#x3D; 2 | x^{(i)}; \theta) \\vdots \p(y^{(i)} &#x3D; k | x^{(i)}; \theta)\end{bmatrix}</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%A4%BA%E4%BE%8B%E4%BB%A3%E7%A0%81"><span class="nav-number">3.1.</span> <span class="nav-text">示例代码</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE"><span class="nav-number">4.</span> <span class="nav-text">参考文献</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Cuiyn</p>
  <div class="site-description" itemprop="description">关注计算机安全文献与计算机领域热门话题</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">39</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">20</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://cuiyn.github.io/2018/01/18/Use-Tensorflow-to-Build-Deep-Learning-Model/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Cuiyn">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Cuiyn's Blog">
      <meta itemprop="description" content="关注计算机安全文献与计算机领域热门话题">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="利用Tensorflow构建深度学习模型 | Cuiyn's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          利用Tensorflow构建深度学习模型
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2018-01-18 01:20:00" itemprop="dateCreated datePublished" datetime="2018-01-18T01:20:00+08:00">2018-01-18</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2023-03-22 22:12:31" itemprop="dateModified" datetime="2023-03-22T22:12:31+08:00">2023-03-22</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <p>本文主要介绍如何使用Tensorflow框架作为深度学习的工具，构建模型并求解问题。</p>
<span id="more"></span>

<h1 id="Tensorflow概述"><a href="#Tensorflow概述" class="headerlink" title="Tensorflow概述"></a>Tensorflow概述</h1><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>TensorFlow是一个开源软件库，用于各种感知和语言理解任务的机器学习。TensorFlow可以运行在多个CPU和GPU。TensorFlow可用于64位Linux、macOS和Windows，以及移动计算平台，包括Android和iOS。</p>
<p>下面给出一张示意图，以描述Tensorflow的工作流程。</p>
<p><img src="/statics/images/20180118/tensors_flowing.gif" alt="Tensorflow数据流图" title="Tensorflow数据流图"></p>
<p>数据流图用“节点”（nodes）和“线”(edges)的有向图来描述数学计算。“节点” 一般用来表示施加的数学操作，但也可以表示数据输入（feed in）的起点，或输出（push out）的终点，或者是读取&#x2F;写入持久变量（persistent variable）的终点。“线”表示“节点”之间的输入&#x2F;输出关系。这些数据“线”可以输运“size可动态调整”的多维数据数组，即“张量”（tensor）。张量从图中流过的直观图像是这个工具取名为“Tensorflow”的原因。一旦输入端的所有张量准备好，节点将被分配到各种计算设备完成异步并行地执行运算。</p>
<h2 id="一个简单示例"><a href="#一个简单示例" class="headerlink" title="一个简单示例"></a>一个简单示例</h2><p>假设我们需要拟合一个平面：$y&#x3D;0.1x_1 + 0.2x_2 + 0.3$。神经网络的表达式为：$y&#x3D;W_1x_1 + W_2x_2 + b$，示意分别如图。</p>
<p><img src="/statics/images/20180118/example.jpg" alt="平面与神经网络模型示意图" title="平面与神经网络模型示意图"></p>
<p>下面针对程序代码说明如何使用Tensorflow求解这个问题。首先构建模型：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 构建模型</span></span><br><span class="line">b = tf.Variable(tf.zeros([<span class="number">1</span>]))</span><br><span class="line">W = tf.Variable(tf.random_uniform([<span class="number">1</span>, <span class="number">2</span>], -<span class="number">1.0</span>, <span class="number">1.0</span>))</span><br><span class="line">y = tf.matmul(W, x_data) + b</span><br></pre></td></tr></table></figure>

<p>这里定义了b、W、y三个参数，b是尺寸为1的张量，W是均匀分布的随机数，取值为[-1.0, 1.0]，尺寸为[1, 2]。y是W与x作矩阵乘法后再加b。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 构造误差函数</span></span><br><span class="line">loss = tf.reduce_mean(tf.square(y - y_data))</span><br></pre></td></tr></table></figure>

<p>这里定义了误差函数，y是预测值，y.data是实际值。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 构造优化器</span></span><br><span class="line">optimizer = tf.train.GradientDescentOptimizer(<span class="number">0.5</span>)</span><br><span class="line">train = optimizer.minimize(loss)</span><br></pre></td></tr></table></figure>

<p>使用梯度下降法进行求解，目的是最小化误差。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 初始化变量</span></span><br><span class="line">init = tf.initialize_all_variables()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动会话</span></span><br><span class="line">sess = tf.Session()</span><br><span class="line">sess.run(init)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练</span></span><br><span class="line"><span class="keyword">for</span> step <span class="keyword">in</span> xrange(<span class="number">0</span>, <span class="number">201</span>):</span><br><span class="line">    sess.run(train)</span><br></pre></td></tr></table></figure>

<p>之后就是套路性质的代码了，初始化变量、启动会话、开始训练。会话（Session）是Tensorflow为了控制和输出文件的执行的语句。</p>
<h2 id="利用多个GPU加速计算"><a href="#利用多个GPU加速计算" class="headerlink" title="利用多个GPU加速计算"></a>利用多个GPU加速计算</h2><p>Tensorflow可以在CPU与GPU间无缝切换。由于GPU的特性，它非常适合机器学习的计算。其工作模型如图。</p>
<p><img src="/statics/images/20180118/tensorflow_GPU.png" alt="多GPU板卡示意图" title="多GPU板卡示意图"></p>
<p>其机制可概括为：在每个GPU上放置单独的模型副本，等所有GPU处理完一批数据后再同步更新模型的参数。这一机制要求所有GPU能够共享模型参数，但在GPU之间传输数据非常慢，因此在CPU上存储和更新所有模型的参数。这样一来，GPU在处理一批新的数据之前会更新一遍的参数。</p>
<p>图中所有的GPU是同步运行的。所有GPU中的梯度会累积并求平均值。模型参数会利用所有模型副本梯度的均值来更新。</p>
<h1 id="MNIST手写数字识别"><a href="#MNIST手写数字识别" class="headerlink" title="MNIST手写数字识别"></a>MNIST手写数字识别</h1><p>当我们开始学习编程的时候，第一件事往往是学习打印”Hello World”。就好比编程入门有Hello World，机器学习入门有MNIST。MNIST是一个入门级的计算机视觉数据集，它包含各种手写数字图片及其标签（告诉我们它是哪个数字），提供了60000行的训练数据集和10000行的测试数据集。下面我们主要利用它来进一步学习。</p>
<h2 id="图像的数据结构"><a href="#图像的数据结构" class="headerlink" title="图像的数据结构"></a>图像的数据结构</h2><p>在计算机中，图像实际上被看作一个矩阵，如图。</p>
<p><img src="/statics/images/20180118/MNIST-Matrix.png" alt="图像数据结构示意图" title="图像数据结构示意图"></p>
<p>这个矩阵可表示为长×宽×色道数。因为示意图是黑白单色，所以只有一个维度。彩色图片有多个维度。</p>
<p>MNIST数据集的长和宽均为28个像素。为便于分析，我们使标签数据是“one-hot vectors”。 一个one-hot向量除了某一位的数字是1以外，其余各维度数字都是0。所以，数字n将表示成一个只有在第n维度（从0开始）数字为1的10维向量。比如，标签0将表示成[1,0,0,0,0,0,0,0,0,0,0]。</p>
<h2 id="softmax回归"><a href="#softmax回归" class="headerlink" title="softmax回归"></a>softmax回归</h2><p>在softmax回归中，我们解决的是多分类问题，类标$y$可以取$k$个不同的值。因此，对于训练集${ (x^{(1)}, y^{(1)}), \ldots, (x^{(m)}, y^{(m)}) }$，我们有$y^{(i)} \in {1, 2, \ldots, k}$。（注意此处的类别下标从1开始，而不是0）。例如，在MNIST数字识别任务中，我们有$k&#x3D;10$个不同的类别。</p>
<p>对于给定的测试输入$x$，我们想用假设函数针对每一个类别j估算出概率值$p(y&#x3D;j丨x)$。也就是说，我们想估计$x$的每一种分类结果出现的概率。因此，我们的假设函数将要输出一个$k$维的向量（向量元素的和为1）来表示这$k$估计的概率值。 具体地说，我们的假设函数$h_{\theta}(x)$形式如下：</p>
<h1 id="h-theta-x-i-x3D-begin-bmatrix-p-y-i-x3D-1-x-i-theta-p-y-i-x3D-2-x-i-theta-vdots-p-y-i-x3D-k-x-i-theta-end-bmatrix"><a href="#h-theta-x-i-x3D-begin-bmatrix-p-y-i-x3D-1-x-i-theta-p-y-i-x3D-2-x-i-theta-vdots-p-y-i-x3D-k-x-i-theta-end-bmatrix" class="headerlink" title="$$h_\theta(x^{(i)}) &#x3D;\begin{bmatrix}p(y^{(i)} &#x3D; 1 | x^{(i)}; \theta) \p(y^{(i)} &#x3D; 2 | x^{(i)}; \theta) \\vdots \p(y^{(i)} &#x3D; k | x^{(i)}; \theta)\end{bmatrix}"></a>$$<br>h_\theta(x^{(i)}) &#x3D;<br>\begin{bmatrix}<br>p(y^{(i)} &#x3D; 1 | x^{(i)}; \theta) \<br>p(y^{(i)} &#x3D; 2 | x^{(i)}; \theta) \<br>\vdots \<br>p(y^{(i)} &#x3D; k | x^{(i)}; \theta)<br>\end{bmatrix}</h1><p>\frac{1}{ \sum_{j&#x3D;1}^{k}{e^{ \theta_j^T x^{(i)} }} }<br>\begin{bmatrix}<br>e^{ \theta_1^T x^{(i)} } \<br>e^{ \theta_2^T x^{(i)} } \<br>\vdots \<br>e^{ \theta_k^T x^{(i)} } \<br>\end{bmatrix}<br>$$</p>
<p>其中$\theta_1, \theta_2, \ldots, \theta_k \in \Re^{n+1}$是模型的参数。请注意$\frac{1}{ \sum_{j&#x3D;1}^{k}{e^{ \theta_j^T x^{(i)} }} }$这一项对概率分布进行归一化，使得所有概率之和为1。</p>
<p>为了方便起见，我们同样使用符号$\theta$来表示全部的模型参数。在实现Softmax回归时，将$\theta$用一个$k \times(n+1)$的矩阵来表示会很方便，该矩阵是将$\theta_1, \theta_2, \ldots, \theta_k$按行罗列起来得到的，如下所示：</p>
<p>$$<br>\theta &#x3D; \begin{bmatrix}<br>-\theta_1^T-\<br>-\theta_2^T- \<br>\vdots \<br>-\theta_k^T- \<br>\end{bmatrix}<br>$$</p>
<p>为表示方便，引入示性函数的概念。$1 { \cdot }$是示性函数，其取值规则为：$1 { True }&#x3D;1$，$1 { False }&#x3D;0$，则代价函数可表示为：</p>
<p>$$<br>J(\theta) &#x3D; - \frac{1}{m} \left[ \sum_{i&#x3D;1}^{m} \sum_{j&#x3D;1}^{k}  1\left{y^{(i)} &#x3D; j\right} \log \frac{e^{\theta_j^T x^{(i)}}}{\sum_{l&#x3D;1}^k e^{ \theta_l^T x^{(i)} }}\right]<br>$$ </p>
<p>注意在Softmax回归中将$x$分类为类别$j$的概率为：</p>
<p>$$<br>p(y^{(i)} &#x3D; j | x^{(i)} ; \theta) &#x3D; \frac{e^{\theta_j^T x^{(i)}}}{\sum_{l&#x3D;1}^k e^{ \theta_l^T x^{(i)}} }<br>$$</p>
<p>对于$J(\theta)$的最小化问题，目前还没有闭式解法。因此，我们使用迭代的优化算法（例如梯度下降法）。经过求导，我们得到梯度公式如下：</p>
<p>$$<br>\nabla_{\theta_j} J(\theta) &#x3D; - \frac{1}{m} \sum_{i&#x3D;1}^{m}{ \left[ x^{(i)} \left( 1{ y^{(i)} &#x3D; j}  - p(y^{(i)} &#x3D; j | x^{(i)}; \theta) \right) \right]  }<br>$$</p>
<p>$\nabla_{\theta_j} J(\theta)$本身是一个向量，它的第$l$个元素$\frac{\partial J(\theta)}{\partial \theta_{jl}}$是$J(\theta)$对$\theta_j$的第$l$个分量的偏导数。有了上面的偏导数公式以后，我们就可以将它代入到梯度下降法等算法中，来最小化$J(\theta)$。 </p>
<h2 id="示例代码"><a href="#示例代码" class="headerlink" title="示例代码"></a>示例代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 占位符</span></span><br><span class="line">x = tf.placeholder(<span class="string">&quot;float&quot;</span>,shape=[<span class="literal">None</span>, <span class="number">784</span>])</span><br><span class="line">y_ = tf.placeholder(<span class="string">&quot;float&quot;</span>,shape=[<span class="literal">None</span>, <span class="number">10</span>])</span><br></pre></td></tr></table></figure>

<p>x不是一个特定的值，而是一个占位符placeholder，我们在TensorFlow运行计算时输入这个值。这里的None表示此张量的第一个维度可以是任何长度的，第二个值784即为28×28（长×宽）。y是预测的概率分布，10即为one-hot向量维度。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">W = tf.Variable(tf.zeros([<span class="number">784</span>,<span class="number">10</span>]))</span><br><span class="line">b = tf.Variable(tf.zeros([<span class="number">10</span>]))</span><br><span class="line">y = tf.nn.softmax(tf.matmul(x,W) + b)</span><br></pre></td></tr></table></figure>

<p>用全为零的张量来初始化W和b。因为我们要学习W和b的值，它们的初值可以随意设置。W的维度是[784，10]，因为我们想要用784维的图片向量乘以它以得到一个10维的证据值向量，每一位对应不同数字类。b的形状是[10]，所以我们可以直接把它加到输出上面。tf.matmul(​​x，W)表示x乘以W，对应之前等式里面的$Wx$，然后再加上b，最后把结果输入到tf.nn.softmax函数里面。</p>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><ul>
<li><a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/TensorFlow">Tensorflow - 维基百科</a></li>
<li><a target="_blank" rel="noopener" href="http://ufldl.stanford.edu/wiki/index.php/Softmax%E5%9B%9E%E5%BD%92">Softmax回归 - Ufldl</a></li>
<li><a target="_blank" rel="noopener" href="http://wiki.jikexueyuan.com/project/tensorflow-zh/tutorials/mnist_beginners.html">MNIST机器学习入门 - 极客学院Wiki</a></li>
</ul>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag"># 机器学习</a>
              <a href="/tags/Batman/" rel="tag"># Batman</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2018/01/10/RPKI%E2%80%98s-Deployment-and-Security/" rel="prev" title="RPKI的部署及安全情况">
                  <i class="fa fa-chevron-left"></i> RPKI的部署及安全情况
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2018/02/01/Bitmap/" rel="next" title="Bitmap算法简介">
                  Bitmap算法简介 <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Cuiyn</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script>

  




  





</body>
</html>
